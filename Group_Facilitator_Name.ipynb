{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lending Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing all necessary libs \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_rows', 99999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('loan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape: \", df.shape)\n",
    "df.columns[df.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping all columns that contain NULL values\n",
    "\n",
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "print('Shape: ', df.shape)\n",
    "df.columns[df.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isna().sum()/len(df.columns))\n",
    "\n",
    "## Columns containing 0 null values\n",
    "print(df.columns[df.isna().sum() > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are 14 more columns that still contains missing values.\n",
    "\n",
    "Filling in the missing values in the columns with the mode/mean/median of the columns can be done.\n",
    "Since there are 14 columns, \n",
    "Lets identify which of the columns would be needed for the analysis and which of the columns would not be needed for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### columns with all unique values can be dropped as they do not provide any information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identifying columns with all unique values\n",
    "print(\"Shape: \",df.shape)\n",
    "# print(df.nunique())\n",
    "df_unique = (df.nunique() == 1) \n",
    "df_unique = df_unique[df_unique == True]\n",
    "print(df_unique)\n",
    "\n",
    "\n",
    "## Dropping columns that contain only 1 unique value\n",
    "df.drop(df_unique.index, axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_unique_and_null_values(df_x):\n",
    "    print(df_x.shape)\n",
    "    # for col in df.columns:\n",
    "    #     print(col, df[col].nunique(), df[col].isna().sum())\n",
    "    na_sum = df_x.isna().sum()\n",
    "    n_unique = df_x.nunique()\n",
    "    na_percentage = ((na_sum/len(df_x)) * 100).astype(int).apply(str) + '%'\n",
    "\n",
    "    na_sum_df = na_sum.reset_index()\n",
    "    n_unique_df = n_unique.reset_index()\n",
    "    na_percentage_df = na_percentage.reset_index()\n",
    "\n",
    "    n_unique_df.columns = ['Column', 'Unique Values']\n",
    "    na_sum_df.columns = ['Column', 'Missing Values']\n",
    "    na_percentage_df.columns = ['Column', 'Missing Percentage']\n",
    "\n",
    "    merged_df = pd.merge( n_unique_df,na_sum_df, on='Column')\n",
    "    merged_df = pd.merge(merged_df, na_percentage_df, on='Column')\n",
    "    print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape: \\n\", df.shape)\n",
    "print_unique_and_null_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns that are not required for analysis\n",
    "(based on the value present in the cells and data dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns(df, columns_to_remove):\n",
    "    df_x = df.copy()\n",
    "    df_x.drop(columns_to_remove, axis=1, inplace=True)\n",
    "    return df_x\n",
    "\n",
    "\n",
    "# Columns that are not required for analysis based on the present value and data dictionary\n",
    "irrelevant_columns = np.array([\n",
    "    # 'id',\n",
    "    'member_id',\n",
    "    'url',\n",
    "    'desc',\n",
    "    'title',\n",
    "    'zip_code',\n",
    "    'addr_state',\n",
    "])\n",
    "\n",
    "print(\"irrelevant_columns.shape: \", irrelevant_columns.shape)\n",
    "\n",
    "df_1 = remove_columns(df, irrelevant_columns)\n",
    "\n",
    "print(\"Shape: \\n\", df_1.shape)\n",
    "print_unique_and_null_values(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns that are post-loan approval and not required for analysis\n",
    "post_approval_columns = np.array([\n",
    "    'emp_title', \n",
    "\n",
    "    'funded_amnt',\n",
    "\n",
    "    'issue_d', \n",
    "    'delinq_2yrs', \n",
    "    \n",
    "    'mths_since_last_delinq',\n",
    "    'mths_since_last_record',\n",
    "\n",
    "    'revol_bal',\n",
    "\n",
    "    \"out_prncp\",\n",
    "    \"out_prncp_inv\",\n",
    "\n",
    "    'total_pymnt',\n",
    "    'total_pymnt_inv',\n",
    "    'total_rec_prncp',\n",
    "    'total_rec_int',\n",
    "    'total_rec_late_fee',\n",
    "\n",
    "    'recoveries',\n",
    "    'collection_recovery_fee', \n",
    "\n",
    "    'last_pymnt_d',\n",
    "    'last_pymnt_amnt', \n",
    "    'next_pymnt_d', \n",
    "    'last_credit_pull_d'\n",
    "    # 'pub_rec_bankruptcies'\n",
    "    ])\n",
    "\n",
    "print(\"post_approval_columns.shape: \",post_approval_columns.shape)\n",
    "\n",
    "df_1 = remove_columns(df_1, post_approval_columns)\n",
    "\n",
    "print(\"Shape: \\n\", df_1.shape)\n",
    "print_unique_and_null_values(df_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing outliers from annual_income\n",
    "sns.boxplot(df_1['annual_inc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_info = df_1.annual_inc.quantile([0.5, 0.75,0.90, 0.95, 0.97,0.98, 0.99,1.0])\n",
    "quantile_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_95_annual_inc = df_1['annual_inc'].quantile(0.99)\n",
    "df_1 = df_1[df_1.annual_inc <= per_95_annual_inc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## emp_length column\n",
    "\n",
    "emp_length_default = df_1['emp_length'].mode()[0]\n",
    "\n",
    "df_1['emp_length'].value_counts()\n",
    "df_1['emp_length'].fillna(emp_length_default, inplace=True)\n",
    "\n",
    "print_unique_and_null_values(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## revol_util column\n",
    "df_1['revol_util'].isna().sum()\n",
    "\n",
    "## since the number of missing values is very low, we can drop the rows with missing values\n",
    "df_1.dropna(axis=0, subset=['revol_util'], inplace=True)\n",
    "\n",
    "print_unique_and_null_values(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pub_rec_bankruptcies column\n",
    "\n",
    "df_1['pub_rec_bankruptcies'].value_counts()\n",
    "\n",
    "## records with loan_status == 'Current', should not be considered for analysis, since the loan_status is not final\n",
    "df_1= df_1[ df_1['loan_status'] != 'Current' ]\n",
    "\n",
    "\n",
    "## records with loan_status == 'Fully Paid', probabily have pub_rec_bankruptcies == 0\n",
    "# df_1['pub_rec_bankruptcies'] = np.where(df_1['loan_status'] == 'Fully Paid', 0, df_1['pub_rec_bankruptcies'])\n",
    "\n",
    "print_unique_and_null_values(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pub_rec_bankruptcies column\n",
    "df_1_pub_rec_bankruptcies_na = df_1[ df_1['pub_rec_bankruptcies'].isna()]\n",
    "\n",
    "count = df_1['loan_status'].value_counts()\n",
    "na_len =  df_1_pub_rec_bankruptcies_na['loan_status'].value_counts()\n",
    "\n",
    "print(count)\n",
    "print(na_len)\n",
    "print('\\n',(na_len/count)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## since the ratio of missing values is very low, we can drop the rows with missing values\n",
    "df_1.dropna(axis=0, subset=['pub_rec_bankruptcies'], inplace=True)\n",
    "\n",
    "print_unique_and_null_values(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_1.copy()\n",
    "\n",
    "df_2['term'] = df_2['term'].str.extract('(\\d+)').astype(int)\n",
    "df_2['int_rate'] = df_2['int_rate'].str.extract('(\\d+.\\d+)').astype(float)\n",
    "df_2['emp_length'] = df_2['emp_length'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "\n",
    "def standardize_dates(date_str):\n",
    "    if '/' in date_str:\n",
    "        return pd.to_datetime(date_str, format='%d/%m/%Y', errors='coerce').strftime('%Y-%m-%d')\n",
    "    else:\n",
    "        return pd.to_datetime(date_str, format='%b-%y', errors='coerce').strftime('%Y-%m-%d')\n",
    "\n",
    "# df_2['earliest_cr_line'] = df_2['earliest_cr_line'].apply(lambda x: standardize_dates(x))\n",
    "\n",
    "# df_2['earliest_cr_line'] = pd.to_datetime(df_2['earliest_cr_line'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "\n",
    "print(df_2.info())\n",
    "(df_2.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_2.copy()\n",
    "\n",
    "df_3_charged_off = df_3[ df_3['loan_status'] == 'Charged Off']\n",
    "df_3_fully_paid = df_3[ df_3['loan_status'] == 'Fully Paid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_3['loan_status'].value_counts())\n",
    "# df_3['loan_status'].value_counts().plot(kind='bar')\n",
    "\n",
    "\n",
    "sns.countplot(x='loan_status', data=df_2)\n",
    "plt.title('Count of Items in Each Status')\n",
    "plt.xlabel('Loan Status')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.countplot( x='grade', order = ['A', 'B', 'C', 'D', 'E', 'F', 'G'], data=df_3_charged_off)\n",
    "# plt.title('Distribution of Charged Off Loans by Grade')\n",
    "# plt.xlabel('Category')\n",
    "# plt.ylabel('Value')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))  # 1 row, 2 columns\n",
    "\n",
    "axes[0].set_title('Distribution of Fully Paid Loans by Grade')\n",
    "axes[1].set_title('Distribution of Charged Off Loans by Grade')\n",
    "\n",
    "sns.countplot( x='grade', order = ['A', 'B', 'C', 'D', 'E', 'F', 'G'], data=df_3_fully_paid, ax=axes[0])\n",
    "sns.countplot( x='grade', order = ['A', 'B', 'C', 'D', 'E', 'F', 'G'], data=df_3_charged_off, ax=axes[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2, figsize=(10, 6))  # 1 row, 2 columns\n",
    "\n",
    "axes[0][0].set_title('Distribution of Fully Paid Loans by Grade')\n",
    "axes[0][1].set_title('Distribution of Charged Off Loans by Grade')\n",
    "\n",
    "## by subgrades\n",
    "axes[1][0].set_title('Distribution of Fully Paid Loans by Subgrade')\n",
    "axes[1][1].set_title('Distribution of Charged Off Loans by Subgrade')\n",
    "\n",
    "sns.countplot( x='grade', order = ['A', 'B', 'C', 'D', 'E', 'F', 'G'], data=df_3_fully_paid, ax=axes[0][0])\n",
    "sns.countplot( x='grade', order = ['A', 'B', 'C', 'D', 'E', 'F', 'G'], data=df_3_charged_off, ax=axes[0][1])\n",
    "\n",
    "sns.countplot( x='sub_grade', order = ['A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4', 'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5', 'G1', 'G2', 'G3', 'G4', 'G5'], data=df_3_fully_paid, ax=axes[1][0])\n",
    "sns.countplot( x='sub_grade', order = ['A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4', 'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5', 'G1', 'G2', 'G3', 'G4', 'G5'], data=df_3_charged_off, ax=axes[1][1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['sub_grade'] = pd.to_numeric(df_3.sub_grade.apply(lambda x : x[-1]))\n",
    "df_3_charged_off = df_3[ df_3['loan_status'] == 'Charged Off']\n",
    "df_3_fully_paid = df_3[ df_3['loan_status'] == 'Fully Paid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots( figsize=(12, 6))  # 1 row, 2 columns\n",
    "\n",
    "axes.set_title('Distribution of Charged Off Loans by Grade')\n",
    "sns.countplot( x='grade', order = ['A', 'B', 'C', 'D', 'E', 'F', 'G'], hue = 'sub_grade', data=df_3_charged_off )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_3_charged_off['purpose'].value_counts())\n",
    "\n",
    "ig, ax = plt.subplots(figsize = (10,8))\n",
    "sns.countplot(x ='purpose', data=df_3_charged_off)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the number of records for 'debt_consolidation' is very high,let try using a log scale\n",
    "ig, ax = plt.subplots(figsize = (10,8))\n",
    "sns.countplot(y ='purpose', data=df_3_charged_off)\n",
    "ax.set(xscale = 'log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_3['home_ownership'].value_counts())\n",
    "\n",
    "fig, axes = plt.subplots( figsize=(12, 6))\n",
    "axes.set_title('Distribution of Charged Off Loans by Home Ownership')\n",
    "sns.countplot( x='home_ownership', order=[ 'RENT', 'MORTGAGE', 'OWN', 'OTHER'], data=df_3_charged_off)\n",
    "axes.set(yscale = 'log')  # since the count of 'OTHER' is very low\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_3['home_ownership'].value_counts())\n",
    "\n",
    "fig, axes = plt.subplots( figsize=(12, 6))\n",
    "axes.set_title('Distribution of Charged Off Loans by Home Ownership')\n",
    "sns.countplot( x='home_ownership', order=[ 'RENT', 'MORTGAGE', 'OWN', 'OTHER'], data=df_3_charged_off)\n",
    "axes.set(yscale = 'log')  # since the count of 'OTHER' is very low\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_3['verification_status'].value_counts())\n",
    "\n",
    "fig, axes = plt.subplots( figsize=(12, 6))\n",
    "axes.set_title('Distribution of Charged Off Loans by Verification Status')\n",
    "sns.countplot( x='verification_status', order=['Not Verified', 'Source Verified', 'Verified'], data=df_3_charged_off)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['revol_util'] = df_3['revol_util'].str.extract('(\\d+.\\d+)').astype(float)\n",
    "\n",
    "df_3['revol_util_groups'] = pd.cut(df_3['revol_util'], bins=5,precision =0,labels=['0-20','20-40','40-60','60-80','80-100'])\n",
    "\n",
    "df_3_charged_off = df_3[ df_3['loan_status'] == 'Charged Off']\n",
    "df_3_fully_paid = df_3[ df_3['loan_status'] == 'Fully Paid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots( figsize=(12, 6))\n",
    "axes.set_title('Distribution of Charged Off Loans by Revolving Utilization')\n",
    "sns.countplot( x='revol_util_groups', data=df_3_charged_off)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_3_charged_off['loan_amnt'].describe())\n",
    "\n",
    "fig, axes = plt.subplots( figsize=(12, 6))\n",
    "axes.set_title('Distribution of Charged Off Loans by Loan Amount')\n",
    "sns.histplot( x='loan_amnt', data=df_3_charged_off, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_3_charged_off['term'].value_counts())\n",
    "\n",
    "fig, axes = plt.subplots( figsize=(12, 6))\n",
    "axes.set_title('Distribution of Charged Off Loans by Term')\n",
    "sns.countplot( x='term', data=df_3_charged_off)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_3['int_rate'].describe())\n",
    "df_3['int_rate_groups'] = pd.cut(df_3['int_rate'], bins=5,precision =0,labels=['5%-9%','9%-13%','13%-17%','17%-21%','21%-24%'])\n",
    "\n",
    "df_3_charged_off = df_3[ df_3['loan_status'] == 'Charged Off']\n",
    "df_3_fully_paid = df_3[ df_3['loan_status'] == 'Fully Paid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots( figsize=(12, 6))\n",
    "axes.set_title('Distribution of Charged Off Loans by Interest Rate')\n",
    "sns.countplot( x='int_rate_groups', data=df_3_charged_off)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_3_charged_off['int_rate'].describe())\n",
    "# df_3['int_rate_groups'].value_counts()\n",
    "\n",
    "# print(df_3['int_rate'].describe())\n",
    "bin_4 = df_3.copy()\n",
    "bin_4['int_rate_groups'] = pd.cut(df_3_charged_off['int_rate'], bins=4,precision =0,labels=['5%-10%','10%-15%','15%-20%','20%-25%'])\n",
    "\n",
    "fig, axes = plt.subplots( figsize=(12, 6))\n",
    "axes.set_title('Distribution of Charged Off Loans by Interest Rate')\n",
    "sns.countplot( x='int_rate_groups', data=bin_4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_10 = df_3.copy()\n",
    "bin_10['int_rate_groups'] = pd.cut(df_3_charged_off['int_rate'], bins=10,precision =0,labels=[\n",
    "    '5%-7%','7%-9%','9%-11%','11%-13%','13%-15%','15%-17%','17%-19%','19%-21%','21%-23%','23%-25%'\n",
    "])\n",
    "\n",
    "fig, axes = plt.subplots( figsize=(12, 6))\n",
    "axes.set_title('Distribution of Charged Off Loans by Interest Rate')\n",
    "sns.countplot( x='int_rate_groups', data=bin_10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_20 = df_3.copy()\n",
    "bin_20['int_rate_groups'] = pd.cut(df_3_charged_off['int_rate'], bins=20,precision =0,labels=[\n",
    "    '5%-6%','6%-7%','7%-8%','8%-9%','9%-10%','10%-11%','11%-12%','12%-13%','13%-14%','14%-15%','15%-16%','16%-17%','17%-18%','18%-19%','19%-20%','20%-21%','21%-22%','22%-23%','23%-24%','24%-25%'\n",
    "])\n",
    "\n",
    "fig, axes = plt.subplots( figsize=(12, 6))\n",
    "axes.set_title('Distribution of Charged Off Loans by Interest Rate')\n",
    "sns.countplot( x='int_rate_groups', data=bin_20)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_4 = df_3_charged_off.copy()\n",
    "bin_4['int_rate_groups'] = pd.cut(bin_4['int_rate'], bins=4,precision =0,labels=['5%-10%','10%-15%','15%-20%','20%-25%'])\n",
    "\n",
    "bin_5 = df_3_charged_off.copy()\n",
    "bin_5['int_rate_groups'] = pd.cut(bin_5['int_rate'], bins=5,precision =0,labels=['5%-9%','9%-13%','13%-17%','17%-21%','21%-24%'])\n",
    "\n",
    "bin_10 = df_3_charged_off.copy()\n",
    "bin_10['int_rate_groups'] = pd.cut(bin_10['int_rate'], bins=10,precision =0,labels=[\n",
    "    '5%-7%','7%-9%','9%-11%','11%-13%','13%-15%','15%-17%','17%-19%','19%-21%','21%-23%','23%-25%'\n",
    "])\n",
    "\n",
    "bin_20 = df_3_charged_off.copy()\n",
    "bin_20['int_rate_groups'] = pd.cut(bin_20['int_rate'], bins=20,precision =0,labels=[\n",
    "    '5%-6%','6%-7%','7%-8%','8%-9%','9%-10%','10%-11%','11%-12%','12%-13%','13%-14%','14%-15%','15%-16%','16%-17%','17%-18%','18%-19%','19%-20%','20%-21%','21%-22%','22%-23%','23%-24%','24%-25%'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2, figsize=(12, 6))\n",
    "\n",
    "axes[0][0].set_title('Distribution of Charged Off Loans by Interest Rate in 4 Bins')\n",
    "axes[0][1].set_title('Distribution of Charged Off Loans by Interest Rate in 5 Bins')\n",
    "axes[1][0].set_title('Distribution of Charged Off Loans by Interest Rate in 10 Bins')\n",
    "axes[1][1].set_title('Distribution of Charged Off Loans by Interest Rate in 20 Bins')\n",
    "\n",
    "sns.countplot( x='int_rate_groups', data=bin_4, ax=axes[0][0])\n",
    "sns.countplot( x='int_rate_groups', data=bin_5, ax=axes[0][1])\n",
    "sns.countplot( x='int_rate_groups', data=bin_10, ax=axes[1][0])\n",
    "sns.countplot( x='int_rate_groups', data=bin_20, ax=axes[1][1])\n",
    "\n",
    "# axes[0][0].set_xticklabels(axes[0][0].get_xticklabels(), rotation=45)\n",
    "# axes[0][1].set_xticklabels(axes[0][1].get_xticklabels(), rotation=45)\n",
    "axes[1][0].set_xticklabels(axes[1][0].get_xticklabels(), rotation=45)\n",
    "axes[1][1].set_xticklabels(axes[1][1].get_xticklabels(), rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['installment'].describe()\n",
    "\n",
    "min_value = df_3['installment'].min()\n",
    "max_value = df_3['installment'].max()\n",
    "diff = max_value - min_value\n",
    "bin_size = diff/12\n",
    "\n",
    "print(min_value, max_value, diff, bin_size)\n",
    "\n",
    "bin_edges = [0, 130, 260, 390, 520, 650, 780, 910, 1040, 1170, 1300, 1400]\n",
    "bin_labels = [\n",
    "    '0-130', '131-260', '261-390', '391-520',\n",
    "    '521-650', '651-780', '781-910', '911-1040',\n",
    "    '1041-1170', '1171-1300', '1301-1400'\n",
    "]\n",
    "\n",
    "df_3['installment_groups'] = pd.cut(df_3['installment'], bins=bin_edges, labels=bin_labels, right=False)\n",
    "df_3_charged_off = df_3[ df_3['loan_status'] == 'Charged Off']\n",
    "df_3_fully_paid = df_3[ df_3['loan_status'] == 'Fully Paid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots( figsize=(12, 6))\n",
    "axes.set_title('Distribution of Charged Off Loans by Installment')\n",
    "\n",
    "sns.countplot( x='installment_groups', data=df_3_charged_off)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots( figsize=(12, 6))\n",
    "\n",
    "# emp_length\n",
    "axes.set_title('Distribution of Charged Off Loans by Employment Length')\n",
    "sns.countplot( x='emp_length', data=df_3_charged_off)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['annual_inc'].describe( percentiles=[.25, .5, .75, .9, .95, .99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = df_3['annual_inc'].min()  #4000.0\n",
    "max_value = df_3['annual_inc'].max()  #234996.0\n",
    "diff = max_value - min_value          #230996.0\n",
    "bin_size = diff/12\n",
    "\n",
    "print(min_value, max_value, diff, bin_size)\n",
    "\n",
    "bin_edges = [\n",
    "    0, 20000, 40000, 60000, 80000, 100000, 120000, 140000, 160000, 180000, 200000, 220000, 240000\n",
    "]\n",
    "bin_labels = [\n",
    "    '0-20k', '20k-40k', '40k-60k', '60k-80k', '80k-100k', '100k-120k', '120k-140k', '140k-160k',\n",
    "    '160k-180k', '180k-200k', '200k-220k', '220k-240k'\n",
    "]\n",
    "\n",
    "\n",
    "df_3['annual_inc_groups'] = pd.cut(df_3['annual_inc'], bins=bin_edges, labels=bin_labels, right=False)\n",
    "df_3_charged_off = df_3[ df_3['loan_status'] == 'Charged Off']\n",
    "df_3_fully_paid = df_3[ df_3['loan_status'] == 'Fully Paid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots( figsize=(12, 6))\n",
    "\n",
    "axes.set_title('Distribution of Charged Off Loans by Annual Income')\n",
    "sns.countplot( x='annual_inc_groups', data=df_3_charged_off)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['dti'].describe( percentiles=[.25, .5, .75, .9, .95, .99])\n",
    "\n",
    "\n",
    "min_value = df_3['dti'].min()  #0.0\n",
    "max_value = df_3['dti'].max()  #29.99\n",
    "diff = max_value - min_value   #29.99\n",
    "bin_size = diff/12\n",
    "\n",
    "print(min_value, max_value, diff, bin_size)\n",
    "\n",
    "bin_edges = [\n",
    "    0, 2.5, 5, 7.5, 10, 12.5, 15, 17.5, 20, 22.5, 25, 27.5, 30\n",
    "]\n",
    "\n",
    "bin_labels = [\n",
    "    '0-2.5', '2.5-5', '5-7.5', '7.5-10', '10-12.5', '12.5-15', '15-17.5', '17.5-20',\n",
    "    '20-22.5', '22.5-25', '25-27.5', '27.5-30'\n",
    "]\n",
    "\n",
    "df_3['dti_groups'] = pd.cut(df_3['dti'], bins=bin_edges, precision=0, labels=bin_labels, right=False)\n",
    "df_3_charged_off = df_3[ df_3['loan_status'] == 'Charged Off']\n",
    "df_3_fully_paid = df_3[ df_3['loan_status'] == 'Fully Paid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots( figsize=(12, 6))\n",
    "\n",
    "axes.set_title('Distribution of Charged Off Loans by Debt to Income Ratio')\n",
    "sns.countplot( x='dti_groups', data=df_3_charged_off)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_3_charged_off['inq_last_6mths'].value_counts())\n",
    "\n",
    "fig, axes = plt.subplots( figsize=(12, 6))\n",
    "sns.countplot( x='inq_last_6mths', data=df_3_charged_off)\n",
    "axes.set(yscale = 'log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3_charged_off['open_acc'].value_counts()\n",
    "\n",
    "fig, axes = plt.subplots( figsize=(12, 6))\n",
    "sns.countplot( x='open_acc', data=df_3_charged_off)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3_charged_off['pub_rec'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-variate Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
